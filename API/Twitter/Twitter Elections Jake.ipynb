{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Twitter Elections Jake**<br>\n",
    "*Compsci 209 Final Project*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the instructions here for pulling tweets:<br>\n",
    "https://developer.twitter.com/en/docs/tweets/search/api-reference/premium-search#DataEndpoint\n",
    "\n",
    "Tutorial for pulling geography of tweets:<br>\n",
<<<<<<< HEAD
    "https://stackabuse.com/accessing-the-twitter-api-with-python/"
=======
    "https://stackabuse.com/accessing-the-twitter-api-with-python/\n",
    "\n",
    "Query Parameter:<br>\n",
    "https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 1,
>>>>>>> origin/master
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import Twython\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 2,
>>>>>>> origin/master
   "metadata": {},
   "outputs": [],
   "source": [
    "import config_twitter\n",
    "\n",
    "app_key = config_twitter.api_key\n",
    "app_secret_key = config_twitter.api_secret_key\n",
    "access_token = config_twitter.access_token\n",
    "access_token_secret = config_twitter.access_token_secret\n",
    "\n",
    "user_agent = \"Jake_Schneider\""
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = Twython(app_key, app_secret_key,\n",
=======
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "twython = Twython(app_key, app_secret_key,\n",
>>>>>>> origin/master
    "                  access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 4,
>>>>>>> origin/master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "{'/search/tweets': {'limit': 180, 'remaining': 180, 'reset': 1574130206}}"
      ]
     },
     "execution_count": 6,
=======
       "{'/search/tweets': {'limit': 180, 'remaining': 180, 'reset': 1575934021}}"
      ]
     },
     "execution_count": 4,
>>>>>>> origin/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "twitter.get_application_rate_limit_status()['resources']['search']"
=======
    "twython.get_application_rate_limit_status()['resources']['search']"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 5,
>>>>>>> origin/master
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1293308917,\n",
       " 'id_str': '1293308917',\n",
       " 'name': 'Jake Schneider',\n",
       " 'screen_name': '_jwschneider',\n",
       " 'location': 'Cambridge, MA',\n",
       " 'description': 'Economist. Data Scientist. Entrepreneur. \\nFounder @SchneiderEconomics. Founder @PolicyViews. MPA/ID Candidate @Harvard @Kennedy_School.',\n",
       " 'url': 'https://t.co/KiRNKCPigk',\n",
       " 'entities': {'url': {'urls': [{'url': 'https://t.co/KiRNKCPigk',\n",
       "     'expanded_url': 'http://www.policyviews.com',\n",
       "     'display_url': 'policyviews.com',\n",
       "     'indices': [0, 23]}]},\n",
       "  'description': {'urls': []}},\n",
       " 'protected': False,\n",
<<<<<<< HEAD
       " 'followers_count': 56,\n",
       " 'friends_count': 168,\n",
       " 'listed_count': 0,\n",
       " 'created_at': 'Sun Mar 24 02:33:01 +0000 2013',\n",
       " 'favourites_count': 46,\n",
=======
       " 'followers_count': 59,\n",
       " 'friends_count': 171,\n",
       " 'listed_count': 0,\n",
       " 'created_at': 'Sun Mar 24 02:33:01 +0000 2013',\n",
       " 'favourites_count': 48,\n",
>>>>>>> origin/master
       " 'utc_offset': None,\n",
       " 'time_zone': None,\n",
       " 'geo_enabled': False,\n",
       " 'verified': False,\n",
<<<<<<< HEAD
       " 'statuses_count': 57,\n",
       " 'lang': None,\n",
       " 'status': {'created_at': 'Fri Oct 11 16:06:20 +0000 2019',\n",
       "  'id': 1182688895848214528,\n",
       "  'id_str': '1182688895848214528',\n",
       "  'text': \"Tune in next Friday for the launch of #PolicyViews, the Harvard Kennedy School's student-run video media organizati… https://t.co/q1tO9BRquy\",\n",
       "  'truncated': True,\n",
       "  'entities': {'hashtags': [{'text': 'PolicyViews', 'indices': [38, 50]}],\n",
       "   'symbols': [],\n",
       "   'user_mentions': [],\n",
       "   'urls': [{'url': 'https://t.co/q1tO9BRquy',\n",
       "     'expanded_url': 'https://twitter.com/i/web/status/1182688895848214528',\n",
=======
       " 'statuses_count': 59,\n",
       " 'lang': None,\n",
       " 'status': {'created_at': 'Sun Nov 24 15:52:33 +0000 2019',\n",
       "  'id': 1198630493694169089,\n",
       "  'id_str': '1198630493694169089',\n",
       "  'text': \"@BarackObama Recently #Harvard's student media organization #PolicyViews interviewed your former #ChiefEconomist Ja… https://t.co/L2yL1cfTf7\",\n",
       "  'truncated': True,\n",
       "  'entities': {'hashtags': [{'text': 'Harvard', 'indices': [22, 30]},\n",
       "    {'text': 'PolicyViews', 'indices': [60, 72]},\n",
       "    {'text': 'ChiefEconomist', 'indices': [97, 112]}],\n",
       "   'symbols': [],\n",
       "   'user_mentions': [{'screen_name': 'BarackObama',\n",
       "     'name': 'Barack Obama',\n",
       "     'id': 813286,\n",
       "     'id_str': '813286',\n",
       "     'indices': [0, 12]}],\n",
       "   'urls': [{'url': 'https://t.co/L2yL1cfTf7',\n",
       "     'expanded_url': 'https://twitter.com/i/web/status/1198630493694169089',\n",
>>>>>>> origin/master
       "     'display_url': 'twitter.com/i/web/status/1…',\n",
       "     'indices': [117, 140]}]},\n",
       "  'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>',\n",
       "  'in_reply_to_status_id': None,\n",
       "  'in_reply_to_status_id_str': None,\n",
<<<<<<< HEAD
       "  'in_reply_to_user_id': None,\n",
       "  'in_reply_to_user_id_str': None,\n",
       "  'in_reply_to_screen_name': None,\n",
=======
       "  'in_reply_to_user_id': 813286,\n",
       "  'in_reply_to_user_id_str': '813286',\n",
       "  'in_reply_to_screen_name': 'BarackObama',\n",
>>>>>>> origin/master
       "  'geo': None,\n",
       "  'coordinates': None,\n",
       "  'place': None,\n",
       "  'contributors': None,\n",
       "  'is_quote_status': False,\n",
       "  'retweet_count': 0,\n",
       "  'favorite_count': 0,\n",
       "  'favorited': False,\n",
       "  'retweeted': False,\n",
       "  'possibly_sensitive': False,\n",
       "  'lang': 'en'},\n",
       " 'contributors_enabled': False,\n",
       " 'is_translator': False,\n",
       " 'is_translation_enabled': False,\n",
       " 'profile_background_color': 'C0DEED',\n",
       " 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
       " 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
       " 'profile_background_tile': False,\n",
       " 'profile_image_url': 'http://pbs.twimg.com/profile_images/854774412511412224/ivT24Ng5_normal.jpg',\n",
       " 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/854774412511412224/ivT24Ng5_normal.jpg',\n",
       " 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1293308917/1571192600',\n",
       " 'profile_link_color': '1DA1F2',\n",
       " 'profile_sidebar_border_color': 'C0DEED',\n",
       " 'profile_sidebar_fill_color': 'DDEEF6',\n",
       " 'profile_text_color': '333333',\n",
       " 'profile_use_background_image': True,\n",
       " 'has_extended_profile': False,\n",
       " 'default_profile': True,\n",
       " 'default_profile_image': False,\n",
       " 'can_media_tag': True,\n",
       " 'followed_by': False,\n",
       " 'following': False,\n",
       " 'follow_request_sent': False,\n",
       " 'notifications': False,\n",
       " 'translator_type': 'none',\n",
       " 'suspended': False,\n",
       " 'needs_phone_verification': False}"
      ]
     },
<<<<<<< HEAD
     "execution_count": 7,
=======
     "execution_count": 5,
>>>>>>> origin/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "twitter.verify_credentials()"
=======
    "twython.verify_credentials()"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Search for Conservative Tweets**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query\n",
    "query = {'q': 'conservative',\n",
    "        'result_type': 'popular',\n",
    "        'count': 10,\n",
    "        'lang': 'en',\n",
=======
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q': 'conservative', 'result_type': 'popular', 'count': 1000, 'lang': 'en'}\n"
     ]
    }
   ],
   "source": [
    "# Create query\n",
    "query = {'q': 'conservative',\n",
    "        #'geocode': '37.0902, -95.7129, 1500mi',\n",
    "        'result_type': 'popular',\n",
    "        'count': 1000,\n",
    "        'lang': 'en',\n",
    "#        'until': \"2018-11-06\" \n",
>>>>>>> origin/master
    "        }\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 7,
>>>>>>> origin/master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "{'/search/tweets': {'limit': 180, 'remaining': 180, 'reset': 1574131322}}"
      ]
     },
     "execution_count": 12,
=======
       "{'/search/tweets': {'limit': 180, 'remaining': 180, 'reset': 1575934022}}"
      ]
     },
     "execution_count": 7,
>>>>>>> origin/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "twitter.get_application_rate_limit_status()['resources']['search']"
=======
    "twython.get_application_rate_limit_status()['resources']['search']"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search tweets\n",
    "dict_ = {'user': [], 'date': [], 'text': [], 'favorite_count': []}\n",
    "for status in twitter.search(**query)['statuses']:\n",
    "    dict_['user'].append(status['user']['screen_name'])\n",
    "    dict_['date'].append(status['created_at'])\n",
    "    dict_['text'].append(status['text'])\n",
    "    dict_['favorite_count'].append(status['favorite_count'])"
=======
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# Search tweets\n",
    "dict_ = {'user': [], 'date': [], 'text': [], 'favorite_count': [], 'user_loc': []}\n",
    "for status in twython.search(**query)['statuses']:\n",
    "    dict_['user'].append(status['user']['screen_name'])\n",
    "    dict_['date'].append(status['created_at'])\n",
    "    dict_['text'].append(status['text'])\n",
    "    dict_['favorite_count'].append(status['favorite_count'])\n",
    "    dict_['user_loc'].append(status['user']['location'])\n",
    "\n",
    "\n",
    "    \n",
    "print(len(dict_[\"user\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>user_loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jeremycorbyn</td>\n",
       "      <td>Mon Dec 09 21:40:24 +0000 2019</td>\n",
       "      <td>Refusing to look at a photo will not help our ...</td>\n",
       "      <td>24033</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mrjamesob</td>\n",
       "      <td>Sun Dec 08 23:18:32 +0000 2019</td>\n",
       "      <td>It’s not hard. Vote Conservative if you think ...</td>\n",
       "      <td>22899</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jeremycorbyn</td>\n",
       "      <td>Mon Dec 09 12:32:41 +0000 2019</td>\n",
       "      <td>The Conservative slogan “Get Brexit done” is a...</td>\n",
       "      <td>22027</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>charliekirk11</td>\n",
       "      <td>Sun Dec 08 13:20:34 +0000 2019</td>\n",
       "      <td>This is your daily reminder that Obama weaponi...</td>\n",
       "      <td>20501</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aiannucci</td>\n",
       "      <td>Mon Dec 09 10:29:47 +0000 2019</td>\n",
       "      <td>If you normally vote Conservative I’d like to ...</td>\n",
       "      <td>16058</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JennaEllisEsq</td>\n",
       "      <td>Sun Dec 08 17:41:22 +0000 2019</td>\n",
       "      <td>The Dems are desperately searching for grounds...</td>\n",
       "      <td>14530</td>\n",
       "      <td>Washington, DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dbongino</td>\n",
       "      <td>Mon Dec 09 01:47:22 +0000 2019</td>\n",
       "      <td>Ditch the Drudge Report and follow the real so...</td>\n",
       "      <td>9080</td>\n",
       "      <td>Florida, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OwenJones84</td>\n",
       "      <td>Mon Dec 09 17:47:22 +0000 2019</td>\n",
       "      <td>If a load of certain high profile journalists ...</td>\n",
       "      <td>6305</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Mon Dec 09 09:39:00 +0000 2019</td>\n",
       "      <td>We will get Brexit done and get Parliament wor...</td>\n",
       "      <td>4603</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DLoesch</td>\n",
       "      <td>Mon Dec 09 18:24:29 +0000 2019</td>\n",
       "      <td>I need the godless government’s help raising m...</td>\n",
       "      <td>4065</td>\n",
       "      <td>Texas, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Sun Dec 08 09:30:00 +0000 2019</td>\n",
       "      <td>Under my leadership, a majority Conservative g...</td>\n",
       "      <td>3939</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Andrew_Adonis</td>\n",
       "      <td>Mon Dec 09 18:15:13 +0000 2019</td>\n",
       "      <td>The BBC is having another very bad day of bein...</td>\n",
       "      <td>3425</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dbongino</td>\n",
       "      <td>Sun Dec 08 14:44:24 +0000 2019</td>\n",
       "      <td>Thank you very much for your support of our ne...</td>\n",
       "      <td>2336</td>\n",
       "      <td>Florida, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>normanlamb</td>\n",
       "      <td>Sun Dec 08 12:02:19 +0000 2019</td>\n",
       "      <td>Anyone thinking of voting Conservative on Thur...</td>\n",
       "      <td>1805</td>\n",
       "      <td>norman.lamb.mp@parliament..uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VictoriaLIVE</td>\n",
       "      <td>Mon Dec 09 10:50:56 +0000 2019</td>\n",
       "      <td>Since the election was called, not one Conserv...</td>\n",
       "      <td>784</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user                            date  \\\n",
       "5    jeremycorbyn  Mon Dec 09 21:40:24 +0000 2019   \n",
       "2       mrjamesob  Sun Dec 08 23:18:32 +0000 2019   \n",
       "4    jeremycorbyn  Mon Dec 09 12:32:41 +0000 2019   \n",
       "0   charliekirk11  Sun Dec 08 13:20:34 +0000 2019   \n",
       "3       Aiannucci  Mon Dec 09 10:29:47 +0000 2019   \n",
       "6   JennaEllisEsq  Sun Dec 08 17:41:22 +0000 2019   \n",
       "1        dbongino  Mon Dec 09 01:47:22 +0000 2019   \n",
       "10    OwenJones84  Mon Dec 09 17:47:22 +0000 2019   \n",
       "14   BorisJohnson  Mon Dec 09 09:39:00 +0000 2019   \n",
       "9         DLoesch  Mon Dec 09 18:24:29 +0000 2019   \n",
       "13   BorisJohnson  Sun Dec 08 09:30:00 +0000 2019   \n",
       "11  Andrew_Adonis  Mon Dec 09 18:15:13 +0000 2019   \n",
       "8        dbongino  Sun Dec 08 14:44:24 +0000 2019   \n",
       "12     normanlamb  Sun Dec 08 12:02:19 +0000 2019   \n",
       "7    VictoriaLIVE  Mon Dec 09 10:50:56 +0000 2019   \n",
       "\n",
       "                                                 text  favorite_count  \\\n",
       "5   Refusing to look at a photo will not help our ...           24033   \n",
       "2   It’s not hard. Vote Conservative if you think ...           22899   \n",
       "4   The Conservative slogan “Get Brexit done” is a...           22027   \n",
       "0   This is your daily reminder that Obama weaponi...           20501   \n",
       "3   If you normally vote Conservative I’d like to ...           16058   \n",
       "6   The Dems are desperately searching for grounds...           14530   \n",
       "1   Ditch the Drudge Report and follow the real so...            9080   \n",
       "10  If a load of certain high profile journalists ...            6305   \n",
       "14  We will get Brexit done and get Parliament wor...            4603   \n",
       "9   I need the godless government’s help raising m...            4065   \n",
       "13  Under my leadership, a majority Conservative g...            3939   \n",
       "11  The BBC is having another very bad day of bein...            3425   \n",
       "8   Thank you very much for your support of our ne...            2336   \n",
       "12  Anyone thinking of voting Conservative on Thur...            1805   \n",
       "7   Since the election was called, not one Conserv...             784   \n",
       "\n",
       "                         user_loc  \n",
       "5                              UK  \n",
       "2                          London  \n",
       "4                              UK  \n",
       "0                     Phoenix, AZ  \n",
       "3                                  \n",
       "6                  Washington, DC  \n",
       "1                    Florida, USA  \n",
       "10                         London  \n",
       "14                 United Kingdom  \n",
       "9                      Texas, USA  \n",
       "13                 United Kingdom  \n",
       "11                                 \n",
       "8                    Florida, USA  \n",
       "12  norman.lamb.mp@parliament..uk  \n",
       "7                                  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Structure data in a pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(dict_)\n",
    "df.sort_values(by='favorite_count', inplace=True, ascending=False)\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic Heat Map\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "import gmplot\n",
    "\n",
    "geolocator = Nominatim(user_agent = user_agent)\n",
    "\n",
    "# Go through all tweets and add locations to 'coordinates' dictionary\n",
    "coordinates = {'latitude': [], 'longitude': []}\n",
    "for count, user_loc in enumerate(df.user_loc):\n",
    "    try:\n",
    "        location = geolocator.geocode(user_loc)\n",
    "        \n",
    "        # If coordinates are found for location\n",
    "        if location:\n",
    "            coordinates['latitude'].append(location.latitude)\n",
    "            coordinates['longitude'].append(location.longitude)\n",
    "            \n",
    "    # If too many connection requests\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "# Instantiate and center a GoogleMapPlotter object to show our map\n",
    "gmap = gmplot.GoogleMapPlotter(30, 0, 3)\n",
    "\n",
    "# Insert points on the map passing a list of latitudes and longitudes\n",
    "gmap.heatmap(coordinates['latitude'], coordinates['longitude'], radius=20)\n",
    "\n",
    "# Save the map to html file\n",
    "gmap.draw(\"/Users/jschneids13/Desktop/Harvard Kennedy School MPA-ID/Semesters/Semester 3, Fall 2019/COMPSCI 109 Data Science/Final Project/CS109a-Group-81-Final-Project/API/heat_map.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Premium Query: Example \"Conservative\"** <br>\n",
    "<br>\n",
    "Resource from Luca Hammer: https://lucahammer.com/2019/11/05/collecting-old-tweets-with-the-twitter-premium-api-and-python/ <br>\n",
    "<br>\n",
    "Search Query Parameters from Fresh Van Roote: https://freshvanroot.com/blog/2019/twitter-search-guide-by-luca/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: searchtweets in /opt/anaconda3/lib/python3.7/site-packages (1.7.4)\r\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.7/site-packages (from searchtweets) (2.22.0)\r\n",
      "Requirement already satisfied: tweet-parser in /opt/anaconda3/lib/python3.7/site-packages (from searchtweets) (1.13.2)\r\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.7/site-packages (from searchtweets) (5.1.2)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests->searchtweets) (2.8)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests->searchtweets) (2019.9.11)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests->searchtweets) (3.0.4)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests->searchtweets) (1.24.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install searchtweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/searchtweets/credentials.py:34: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  search_creds = yaml.load(f)[yaml_key]\n",
      "Grabbing bearer token from OAUTH\n"
     ]
    }
   ],
   "source": [
    "# Load OAUTH Bearer Token Credentials\n",
    "\n",
    "from searchtweets import load_credentials\n",
    "\n",
    "premium_search_args = load_credentials(\"twitter_keys_full_archive.yaml\",\n",
    "                                       yaml_key=\"search_tweets_api\",\n",
    "                                       env_overwrite=False)\n",
    "#print(premium_search_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create General Payload Rule\n",
    "\n",
    "from searchtweets import gen_rule_payload\n",
    "\n",
    "rule = gen_rule_payload(\"Conservative\", \n",
    "                        results_per_call=100,\n",
    "                        from_date=\"2018-08-06\",\n",
    "                        to_date=\"2018-11-06\"\n",
    "                        #next_results=1\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResultStream: \n",
      "\t{\n",
      "    \"username\": null,\n",
      "    \"endpoint\": \"https://api.twitter.com/1.1/tweets/search/fullarchive/elections.json\",\n",
      "    \"rule_payload\": {\n",
      "        \"query\": \"Conservative\",\n",
      "        \"maxResults\": 100,\n",
      "        \"toDate\": \"201811060000\",\n",
      "        \"fromDate\": \"201808060000\"\n",
      "    },\n",
      "    \"tweetify\": true,\n",
      "    \"max_results\": 100\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Create Result Stream\n",
    "# Pagination: https://github.com/twitterdev/search-tweets-python/issues/47\n",
    "# Try max_pages function\n",
    "\n",
    "from searchtweets import ResultStream\n",
    "\n",
    "rs = ResultStream(rule_payload=rule,\n",
    "                  max_results=100, #twitter allows 900 max per call\n",
    "                  #max_pages=100,\n",
    "                  #max_id=1001,\n",
    "                  **premium_search_args)\n",
    "print(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collect Tweets Using 'collect_results'\n",
    "#from searchtweets import collect_results\n",
    "#\n",
    "#results_list = collect_results(rule,\n",
    "#                              max_results=500,\n",
    "#                              result_stream_args= premium_search_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## View length results_list\n",
    "#\n",
    "#print(len(results_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## View results_list\n",
    "#\n",
    "#results_list[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrying request; current status code: 429\n",
      "retrying request; current status code: 429\n",
      "retrying request; current status code: 429\n",
      "HTTP Error code: 429: Request exceeds account’s current package request limits. Please upgrade your package and retry or contact Twitter about enterprise access.\n",
      "Rule payload: {'query': 'Conservative', 'maxResults': 100, 'toDate': '201811060000', 'fromDate': '201808060000'}\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-8979b01b7e37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'twitter_premium_api_demo_conservative.jsonl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/searchtweets/result_stream.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/searchtweets/result_stream.py\u001b[0m in \u001b[0;36mexecute_request\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m         resp = request(session=self.session,\n\u001b[1;32m    259\u001b[0m                        \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m                        rule_payload=self.rule_payload)\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_requests\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mResultStream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_request_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/searchtweets/result_stream.py\u001b[0m in \u001b[0;36mretried_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HTTP Error code: {}: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rule payload: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rule_payload\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Collect the Tweets\n",
    "\n",
    "import json\n",
    "\n",
    "with open('twitter_premium_api_demo_conservative.jsonl', 'a', encoding='utf-8') as f:\n",
    "    n = 0\n",
    "    for tweet in rs.stream():\n",
    "        n += 1\n",
    "        if n % 10 == 0:\n",
    "            print('{0}: {1}'.format(str(n), tweet['created_at']))\n",
    "        json.dump(tweet, f)\n",
    "        f.write('\\n')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Date Function for For Loop\n",
    "from datetime import timedelta, date, datetime, time\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "dates = []\n",
    "start_date = datetime(2018, 10, 6, 15, 0)\n",
    "end_date = datetime(2018, 11, 7, 15, 0)\n",
    "for single_date in daterange(start_date, end_date):\n",
    "    #print(single_date.strftime(\"%Y-%m-%d\"))\n",
    "    dates.append(str(single_date))\n",
    "\n",
    "print(dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create For Loop To Pull Max Tweets\n",
    "\n",
    "premium_search_args = load_credentials(\"twitter_keys_full_archive.yaml\",\n",
    "                                       yaml_key=\"search_tweets_api\",\n",
    "                                       env_overwrite=False)\n",
    "\n",
    "for date in dates:\n",
    "    #date = datetime.strptime(str(day), \"%Y-%m-%d\")\n",
    "    print(date)\n",
    "    rule = gen_rule_payload(\"Conservative\", \n",
    "                        results_per_call=100,\n",
    "                        from_date= date[:-8]+str(\"12:00\"), # 12:00pm\n",
    "                        to_date= date[:-3] # 3:00pm\n",
    "                        #next_results=1\n",
    "                       )\n",
    "    print(rule)\n",
    "    \n",
    "    rs = ResultStream(rule_payload=rule,\n",
    "                      max_results=500, #twitter allows 900 max per call\n",
    "                      #max_id=1001,\n",
    "                      **premium_search_args)\n",
    "    \n",
    "    with open('twitter_conservative.jsonl', 'a', encoding='utf-8') as f:\n",
    "        n = 0\n",
    "        for tweet in rs.stream():\n",
    "            n += 1\n",
    "            if n % 10 == 0:\n",
    "                print('{0}: {1}'.format(str(n), tweet['created_at']))\n",
    "                json.dump(tweet, f)\n",
    "                f.write('\\n')\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requests_cache\n",
    "!pip install requests-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to add cacheing to avoid rate limiting\n",
    "\n",
    "import requests_cache\n",
    "requests_cache.install_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Cacheing\n",
    "## This code needs to be changed to twitter\n",
    "## Possible link for pagination: https://stackoverflow.com/questions/14265082/query-regarding-pagination-in-tweepy-get-followers-of-a-particular-twitter-use\n",
    "## Here's another: https://bhaskarvk.github.io/2015/01/how-to-use-twitters-search-rest-api-most-effectively./\n",
    "## Pages in tweepy: https://medium.com/@dmitryrastorguev/sentiment-analysis-of-twitter-timelines-61c73eeacedf\n",
    "\n",
    "#import time\n",
    "#from IPython.core.display import clear_output\n",
    "#\n",
    "#responses = []\n",
    "#\n",
    "#page = 1\n",
    "#total_pages = 99999 # this is just a dummy number so the loop starts\n",
    "#\n",
    "#while page <= total_pages:\n",
    "#    payload = {\n",
    "#        'method': 'chart.gettopartists',\n",
    "#        'limit': 500,\n",
    "#        'page': page\n",
    "#    }\n",
    "#\n",
    "#    # print some output so we can see the status\n",
    "#    print(\"Requesting page {}/{}\".format(page, total_pages))\n",
    "#    # clear the output to make things neater\n",
    "#    clear_output(wait = True)\n",
    "#\n",
    "#    # make the API call\n",
    "#    response = lastfm_get(payload)\n",
    "#\n",
    "#    # if we get an error, print the response and halt the loop\n",
    "#    if response.status_code != 200:\n",
    "#        print(response.text)\n",
    "#        break\n",
    "#\n",
    "#    # extract pagination info\n",
    "#    page = int(response.json()['artists']['@attr']['page'])\n",
    "#    total_pages = int(response.json()['artists']['@attr']['totalPages'])\n",
    "#\n",
    "#    # append response\n",
    "#    responses.append(response)\n",
    "#\n",
    "#    # if it's not a cached result, sleep\n",
    "#    if not getattr(response, 'from_cache', False):\n",
    "#        time.sleep(0.25)\n",
    "#\n",
    "#    # increment the page number\n",
    "#    page += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Json File and Convert to PD Dataframe\n",
    "\n",
    "tweets_conservative_df = pd.read_json('twitter_premium_api_demo_conservative.jsonl', lines=True)\n",
    "tweets_conservative_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Df Collumns\n",
    "tweets_conservative_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Location Data through \"GEO\"\n",
    "tweets_conservative_df[[\"geo\", \"coordinates\", \"place\", \"user\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View User Information through \"User\"\n",
    "print(len(tweets_conservative_df))\n",
    "\n",
    "for loc in range(0,len(tweets_conservative_df)):\n",
    "    print(tweets_conservative_df[\"user\"][loc][\"location\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Streamer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import TwythonStreamer\n",
    "import csv\n",
    "\n",
    "# Filter out unwanted data\n",
    "def process_tweet(tweet):\n",
    "    d = {}\n",
    "    d['hashtags'] = [hashtag['text'] for hashtag in tweet['entities']['hashtags']]\n",
    "    d['text'] = tweet['text']\n",
    "    d['user'] = tweet['user']['screen_name']\n",
    "    d['user_loc'] = tweet['user']['location']\n",
    "    return d\n",
    "    \n",
    "    \n",
    "# Create a class that inherits TwythonStreamer\n",
    "class MyStreamer(TwythonStreamer):     \n",
    "\n",
    "    # Received data\n",
    "    def on_success(self, data):\n",
    "\n",
    "        # Only collect tweets in English\n",
    "        if data['lang'] == 'en':\n",
    "            tweet_data = process_tweet(data)\n",
    "            print(tweet_data)\n",
    "#            self.save_to_csv(tweet_data)\n",
    "            return tweet_data\n",
    "\n",
    "    # Problem with the API\n",
    "    def on_error(self, status_code, data):\n",
    "        print(status_code, data)\n",
    "        self.disconnect()\n",
    "        \n",
    "    # Save each tweet to csv file\n",
    "#    def save_to_csv(self, tweet):\n",
    "#        with open(r'saved_tweets_conservative.csv', 'a') as file:\n",
    "#            writer = csv.writer(file)\n",
    "#            writer.writerow(list(tweet.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate from our streaming class\n",
    "#stream = MyStreamer(app_key, app_secret_key,\n",
    "#                  access_token, access_token_secret)\n",
    "## Start the stream\n",
    "#tweets = stream.statuses.filter(track='conservative')"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
