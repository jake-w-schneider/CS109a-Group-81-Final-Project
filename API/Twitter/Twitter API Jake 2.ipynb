{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Twitter API Jake 2** <br>\n",
    "*Compsci 109 Project*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import Twython\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config_twitter\n",
    "\n",
    "app_key = config_twitter.api_key\n",
    "app_secret_key = config_twitter.api_secret_key\n",
    "access_token = config_twitter.access_token\n",
    "access_token_secret = config_twitter.access_token_secret\n",
    "bearer_token = config_twitter.bearer_token\n",
    "\n",
    "user_agent = \"Jake_Schneider\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b5f6ef97ef00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtweet_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge_dicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapi_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minfer_endpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange_to_count_endpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "import logging\n",
    "import requests\n",
    "try:\n",
    "    import ujson as json\n",
    "except ImportError:\n",
    "    import json\n",
    "from tweet_parser.tweet import Tweet\n",
    "\n",
    "from utils import merge_dicts\n",
    "\n",
    "from .api_utils import infer_endpoint, change_to_count_endpoint\n",
    "\n",
    "from ._version import VERSION\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def make_session(username=None, password=None, bearer_token=None, extra_headers_dict=None): \n",
    "    \"\"\"Creates a Requests Session for use. Accepts a bearer token\n",
    "    for premiums users and will override username and password information if\n",
    "    present.\n",
    "\n",
    "    Args:\n",
    "        username (str): username for the session\n",
    "        password (str): password for the user\n",
    "        bearer_token (str): token for a premium API user.\n",
    "    \"\"\"\n",
    "\n",
    "    if password is None and bearer_token is None:\n",
    "        logger.error(\"No authentication information provided; \"\n",
    "                     \"please check your object\")\n",
    "        raise KeyError\n",
    "\n",
    "    session = requests.Session()\n",
    "    session.trust_env = False\n",
    "    headers = {'Accept-encoding': 'gzip',\n",
    "               'User-Agent': 'twitterdev-search-tweets-python/' + VERSION}\n",
    "    if bearer_token:\n",
    "        logger.info(\"using bearer token for authentication\")\n",
    "        headers['Authorization'] = \"Bearer {}\".format(bearer_token)\n",
    "        session.headers = headers\n",
    "    else:\n",
    "        logger.info(\"using username and password for authentication\")\n",
    "        session.auth = username, password\n",
    "        session.headers = headers\n",
    "    if extra_headers_dict:\n",
    "        headers.update(extra_headers_dict) \n",
    "    return session\n",
    "\n",
    "\n",
    "\n",
    "def retry(func):\n",
    "    \"\"\"\n",
    "    Decorator to handle API retries and exceptions. Defaults to three retries.\n",
    "\n",
    "    Args:\n",
    "        func (function): function for decoration\n",
    "\n",
    "    Returns:\n",
    "        decorated function\n",
    "\n",
    "    \"\"\"\n",
    "    def retried_func(*args, **kwargs):\n",
    "        max_tries = 3\n",
    "        tries = 0\n",
    "        while True:\n",
    "            try:\n",
    "                resp = func(*args, **kwargs)\n",
    "\n",
    "            except requests.exceptions.ConnectionError as exc:\n",
    "                exc.msg = \"Connection error for session; exiting\"\n",
    "                raise exc\n",
    "\n",
    "            except requests.exceptions.HTTPError as exc:\n",
    "                exc.msg = \"HTTP error for session; exiting\"\n",
    "                raise exc\n",
    "\n",
    "            if resp.status_code != 200 and tries < max_tries:\n",
    "                logger.warning(\"retrying request; current status code: {}\"\n",
    "                               .format(resp.status_code))\n",
    "                tries += 1\n",
    "                # mini exponential backoff here.\n",
    "                time.sleep(tries ** 2)\n",
    "                continue\n",
    "\n",
    "            break\n",
    "\n",
    "        if resp.status_code != 200:\n",
    "            error_message = resp.json()[\"error\"][\"message\"]\n",
    "            logger.error(\"HTTP Error code: {}: {}\".format(resp.status_code, error_message))\n",
    "            logger.error(\"Rule payload: {}\".format(kwargs[\"rule_payload\"]))\n",
    "            raise requests.exceptions.HTTPError\n",
    "\n",
    "        return resp\n",
    "\n",
    "    return retried_func\n",
    "\n",
    "\n",
    "\n",
    "@retry\n",
    "def request(session, url, rule_payload, **kwargs):\n",
    "    \"\"\"\n",
    "    Executes a request with the given payload and arguments.\n",
    "\n",
    "    Args:\n",
    "        session (requests.Session): the valid session object\n",
    "        url (str): Valid API endpoint\n",
    "        rule_payload (str or dict): rule package for the POST. If you pass a\n",
    "            dictionary, it will be converted into JSON.\n",
    "    \"\"\"\n",
    "    if isinstance(rule_payload, dict):\n",
    "        rule_payload = json.dumps(rule_payload)\n",
    "    logger.debug(\"sending request\")\n",
    "    result = session.post(url, data=rule_payload, **kwargs)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "class ResultStream:\n",
    "    \"\"\"\n",
    "    Class to represent an API query that handles two major functionality\n",
    "    pieces: wrapping metadata around a specific API call and automatic\n",
    "    pagination of results.\n",
    "\n",
    "    Args:\n",
    "        username (str): username for enterprise customers\n",
    "        password (str): password for enterprise customers\n",
    "        bearer_token (str): bearer token for premium users\n",
    "        endpoint (str): API endpoint; see your console at developer.twitter.com\n",
    "        rule_payload (json or dict): payload for the post request\n",
    "        max_results (int): max number results that will be returned from this\n",
    "        instance. Note that this can be slightly lower than the total returned\n",
    "        from the API call  - e.g., setting ``max_results = 10`` would return\n",
    "        ten results, but an API call will return at minimum 100 results.\n",
    "        tweetify (bool): If you are grabbing tweets and not counts, use the\n",
    "            tweet parser library to convert each raw tweet package to a Tweet\n",
    "            with lazy properties.\n",
    "        max_requests (int): A hard cutoff for the number of API calls this\n",
    "        instance will make. Good for testing in sandbox premium environments. \n",
    "        extra_headers_dict (dict): custom headers to add\n",
    "\n",
    "\n",
    "    Example:\n",
    "        >>> rs = ResultStream(**search_args, rule_payload=rule, max_pages=1)\n",
    "        >>> results = list(rs.stream())\n",
    "\n",
    "    \"\"\"\n",
    "    # leaving this here to have an API call counter for ALL objects in your\n",
    "    # session, helping with usage of the convenience functions in the library.\n",
    "    session_request_counter = 0\n",
    "\n",
    "    def __init__(self, endpoint, rule_payload, username=None, password=None,\n",
    "                 bearer_token=None, extra_headers_dict=None, max_results=500,\n",
    "                 tweetify=True, max_requests=None, **kwargs):\n",
    "\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.bearer_token = bearer_token\n",
    "        self.extra_headers_dict = extra_headers_dict\n",
    "        if isinstance(rule_payload, str):\n",
    "            rule_payload = json.loads(rule_payload)\n",
    "        self.rule_payload = rule_payload\n",
    "        self.tweetify = tweetify\n",
    "        # magic number of max tweets if you pass a non_int\n",
    "        self.max_results = (max_results if isinstance(max_results, int)\n",
    "                            else 10 ** 15)\n",
    "\n",
    "        self.total_results = 0\n",
    "        self.n_requests = 0\n",
    "        self.session = None\n",
    "        self.current_tweets = None\n",
    "        self.next_token = None\n",
    "        self.stream_started = False\n",
    "        self._tweet_func = Tweet if tweetify else lambda x: x\n",
    "        # magic number of requests!\n",
    "        self.max_requests = (max_requests if max_requests is not None\n",
    "                             else 10 ** 9)\n",
    "        self.endpoint = (change_to_count_endpoint(endpoint)\n",
    "                         if infer_endpoint(rule_payload) == \"counts\"\n",
    "                         else endpoint)\n",
    "        # validate_count_api(self.rule_payload, self.endpoint)\n",
    "\n",
    "    def stream(self):\n",
    "        \"\"\"\n",
    "        Main entry point for the data from the API. Will automatically paginate\n",
    "        through the results via the ``next`` token and return up to ``max_results``\n",
    "        tweets or up to ``max_requests`` API calls, whichever is lower.\n",
    "\n",
    "        Usage:\n",
    "            >>> result_stream = ResultStream(**kwargs)\n",
    "            >>> stream = result_stream.stream()\n",
    "            >>> results = list(stream)\n",
    "            >>> # or for faster usage...\n",
    "            >>> results = list(ResultStream(**kwargs).stream())\n",
    "        \"\"\"\n",
    "        self.init_session()\n",
    "        self.check_counts()\n",
    "        self.execute_request()\n",
    "        self.stream_started = True\n",
    "        while True:\n",
    "            for tweet in self.current_tweets:\n",
    "                if self.total_results >= self.max_results:\n",
    "                    break\n",
    "                yield self._tweet_func(tweet)\n",
    "                self.total_results += 1\n",
    "\n",
    "            if self.next_token and self.total_results < self.max_results and self.n_requests <= self.max_requests:\n",
    "                self.rule_payload = merge_dicts(self.rule_payload,\n",
    "                                                {\"next\": self.next_token})\n",
    "                logger.info(\"paging; total requests read so far: {}\"\n",
    "                            .format(self.n_requests))\n",
    "                self.execute_request()\n",
    "            else:\n",
    "                break\n",
    "        logger.info(\"ending stream at {} tweets\".format(self.total_results))\n",
    "        self.current_tweets = None\n",
    "        self.session.close()\n",
    "\n",
    "\n",
    "    def init_session(self):\n",
    "        \"\"\"\n",
    "        Defines a session object for passing requests.\n",
    "        \"\"\"\n",
    "        if self.session:\n",
    "            self.session.close()\n",
    "        self.session = make_session(self.username,\n",
    "                                    self.password,\n",
    "                                    self.bearer_token,\n",
    "                                    self.extra_headers_dict)\n",
    "\n",
    "\n",
    "    def check_counts(self):\n",
    "        \"\"\"\n",
    "        Disables tweet parsing if the count API is used.\n",
    "        \"\"\"\n",
    "        if \"counts\" in re.split(\"[/.]\", self.endpoint):\n",
    "            logger.info(\"disabling tweet parsing due to counts API usage\")\n",
    "            self._tweet_func = lambda x: x\n",
    "\n",
    "\n",
    "    def execute_request(self):\n",
    "        \"\"\"\n",
    "        Sends the request to the API and parses the json response.\n",
    "        Makes some assumptions about the session length and sets the presence\n",
    "        of a \"next\" token.\n",
    "        \"\"\"\n",
    "        if self.n_requests % 20 == 0 and self.n_requests > 1:\n",
    "            logger.info(\"refreshing session\")\n",
    "            self.init_session()\n",
    "\n",
    "        resp = request(session=self.session,\n",
    "                       url=self.endpoint,\n",
    "                       rule_payload=self.rule_payload)\n",
    "        self.n_requests += 1\n",
    "        ResultStream.session_request_counter += 1\n",
    "        resp = json.loads(resp.content.decode(resp.encoding))\n",
    "        self.next_token = resp.get(\"next\", None)\n",
    "        self.current_tweets = resp[\"results\"]\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        repr_keys = [\"username\", \"endpoint\", \"rule_payload\",\n",
    "                     \"tweetify\", \"max_results\"]\n",
    "        str_ = json.dumps(dict([(k, self.__dict__.get(k)) for k in repr_keys]),\n",
    "                          indent=4)\n",
    "        str_ = \"ResultStream: \\n\\t\" + str_\n",
    "        return str_\n",
    "\n",
    "\n",
    "\n",
    "def collect_results(rule, max_results=500, result_stream_args=None):\n",
    "    \"\"\"\n",
    "    Utility function to quickly get a list of tweets from a ``ResultStream``\n",
    "    without keeping the object around. Requires your args to be configured\n",
    "    prior to using.\n",
    "\n",
    "    Args:\n",
    "        rule (str): valid powertrack rule for your account, preferably\n",
    "        generated by the `gen_rule_payload` function.\n",
    "        max_results (int): maximum number of tweets or counts to return from\n",
    "        the API / underlying ``ResultStream`` object.\n",
    "        result_stream_args (dict): configuration dict that has connection\n",
    "        information for a ``ResultStream`` object.\n",
    "\n",
    "    Returns:\n",
    "        list of results\n",
    "\n",
    "    Example:\n",
    "        >>> from searchtweets import collect_results\n",
    "        >>> tweets = collect_results(rule,\n",
    "                                     max_results=500,\n",
    "                                     result_stream_args=search_args)\n",
    "\n",
    "    \"\"\"\n",
    "    if result_stream_args is None:\n",
    "        logger.error(\"This function requires a configuration dict for the \"\n",
    "                     \"inner ResultStream object.\")\n",
    "        raise KeyError\n",
    "\n",
    "    rs = ResultStream(rule_payload=rule,\n",
    "                      max_results=max_results,\n",
    "                      **result_stream_args)\n",
    "    return list(rs.stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
